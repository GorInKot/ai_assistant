# Корпоративный ИИ-ассистент (MVP)

Локальный MVP ассистента для навигации по корпоративным процессам и документам с использованием RAG по локальной базе знаний и генерацией ответа через OpenAI API.

## Что реализовано
- Локальный веб-интерфейс (`localhost`) с:
  - разделом **Чат** (вопрос-ответ по KB);
  - разделом **Документы** (поиск и список рабочих файлов с фильтрами, без `md`);
  - разделом **Действия** (локальная регистрация заявок/обращений в MVP);
  - блоком **Источники** в ответах;
  - ссылками **Открыть / Скачать** для файлов KB;
  - кнопкой **Очистить диалог**.
- RAG-пайплайн:
  1. поиск релевантных фрагментов в локальной KB;
  2. передача в LLM: вопрос + найденный контекст;
  3. генерация ответа только на основе контекста.
- \"Умный\" retrieval для MVP:
  - нормализация словоформ (RU/EN);
  - синонимические теги (например, участники/акторы/роли);
  - BM25-подобное ранжирование + буст по разделам/процессу;
  - LLM rerank кандидатов (опционально, через OpenAI API).
- Обязательное отображение источников в каждом ответе.
- В блоке «Источники» отображаются прикладные документы (PDF/DOC/DOCX), служебные `md`-файлы не показываются.
- Снижение избыточности ответов:
  - определение системы (например, «Что такое ЕКТП?») отвечает кратко, без лишних шагов процесса;
  - для процессных вопросов возвращается только релевантный процесс/чек-лист.
- Короткая память уточнения (1–2 шага):
  - если вопрос неоднозначен, ассистент просит уточнить процесс/систему;
  - следующий короткий ответ пользователя (например, `по ЕКТП`) автоматически дополняет предыдущий вопрос.
- Явный fallback при слабом/отсутствующем контексте:
  - `В базе знаний нет точной информации по вашему вопросу`
  - предложение уточнить вопрос и открыть релевантные документы.
- Локальное логирование (`timestamp`, `user_query`, `selected_sources`, `answer`).
- Локальный журнал действий (`logs/actions.log`) без интеграции с корпоративными ИС.

## Стек
- Python
- FastAPI
- OpenAI API
- Простая HTML/JS страница

## Описание программы
Программа — это локальный корпоративный ИИ-ассистент для сотрудников.

Основная идея:
1. Сотрудник задает вопрос в чате.
2. Ассистент ищет релевантные фрагменты в локальной базе знаний.
3. На основе найденных фрагментов формирует ответ через OpenAI API.
4. Показывает источники (рабочие документы) с кнопками `Открыть/Скачать`.

Ассистент не интегрируется с корпоративными ИС и не выполняет действия в них автоматически — только справка/навигация в рамках MVP.

## Особенности работы
- Ответы строятся по RAG (вопрос + найденные фрагменты), а не «из головы».
- Если вопрос неоднозначен, ассистент просит уточнить процесс/систему.
- Есть короткая память уточнения: ответ вида `по ЕКТП` продолжает предыдущий неоднозначный вопрос.
- В UI-источниках и в разделе «Документы» отображаются рабочие документы (`PDF/DOC/DOCX`), `md` скрыты.
- `md`-файлы можно использовать как внутренние текстовые правила/FAQ для улучшения качества ответов (они участвуют в retrieval).
- При слабом контексте ассистент честно сообщает об отсутствии точной информации.

## Структура проекта
- `app/main.py` — API, маршруты UI/вопросов/файлов/документов/действий, fallback-логика.
- `app/actions.py` — локальное хранение действий (MVP).
- `app/kb.py` — индексация KB, извлечение текста, retrieval, источники.
- `app/llm.py` — вызов OpenAI API.
- `app/logging_utils.py` — запись логов.
- `static/index.html` — локальный веб-интерфейс.
- `knowledge_base/` — база знаний (пример наполнения).
- `demo_queries.md` — тестовые запросы для демонстрации.

## Требования
- Python 3.10+
- OpenAI API key

## Установка
1. Создайте окружение и установите зависимости:
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate
   pip install -r requirements.txt
   ```
2. Настройте переменные окружения:
   ```bash
   cp .env.example .env
   ```
3. В `.env` укажите `OPENAI_API_KEY`.
4. (Опционально) настройки rerank:
   - `ENABLE_LLM_RERANK=1`
   - `RERANK_CANDIDATES=28`
   - `RERANK_TOP_N=16`

## Запуск
```bash
uvicorn app.main:app --reload
```

Откройте: `http://127.0.0.1:8000`

## База знаний
Поддерживаемые форматы: `PDF`, `DOC`, `DOCX`, `MD`.

Переводить все документы в `MD` **не обязательно**.  
Лучший retrieval обычно получается для `MD/DOCX/PDF` с корректно извлекаемым текстом.  
Для `DOC` используется best effort, но файл в любом случае доступен в интерфейсе как документ/источник.

Фиксированная структура (уже создана в примере):

```text
knowledge_base/
├── ЦУС_Строительный_контроль/
│   ├── инструкции/
│   ├── чеклисты/
│   └── faq.md
├── ЕКТП_Транспорт/
│   ├── инструкции/
│   ├── чеклисты/
│   └── faq.md
├── Обучение_и_медосмотр/
│   ├── инструкции/
│   ├── чеклисты/
│   └── faq.md
└── glossary.md
```

Новые файлы, добавленные в `knowledge_base/`, подхватываются после перезапуска приложения (или через `POST /api/reindex`).

## Как наполнять программу (практика)
Рекомендуемый подход:

1. Кладите рабочие документы по процессам в `инструкции/`:
   - пользовательские инструкции;
   - регламенты;
   - шаблоны/формы документов.
2. Для чек-листов используйте `чеклисты/`.
3. Для кратких пояснений и терминов используйте `faq.md` и `glossary.md`.
4. После добавления/обновления файлов делайте переиндексацию:
   ```bash
   curl -X POST http://127.0.0.1:8000/api/reindex
   ```
5. Проверяйте вкладку «Документы» — там должны появиться новые `PDF/DOC/DOCX`.

### Что и куда загружать
- ЕКТП: `knowledge_base/ЕКТП_Транспорт/инструкции/`
- ЦУС: `knowledge_base/ЦУС_Строительный_контроль/инструкции/`
- Обучение/медосмотр: `knowledge_base/Обучение_и_медосмотр/инструкции/`

### Рекомендации по именам файлов
Чтобы было проще фильтровать и искать:
- формы: `Форма_...docx`, `Бланк_...pdf`, `Шаблон_...docx`;
- инструкции: `Инструкция_...pdf`/`Инструкция_...docx`.

### Важный нюанс по форматам
- Переводить всё в `md` не обязательно.
- Для качества retrieval лучше всего подходят `PDF/DOCX` с корректно извлекаемым текстом.
- `DOC` поддерживается в режиме best effort.

## Поведение с DOC
Для `.doc` реализован best effort:
- попытка извлечь текст (конвертеры + fallback);
- если извлечение ненадежно, документ не участвует в retrieval;
- но документ остается доступным в источниках по ссылке на открытие/скачивание.

## Логи
Лог-файл по умолчанию: `logs/assistant.log`.
Формат — JSONL, по одной записи на запрос.

Журнал локальных действий: `logs/actions.log` (JSONL).

## API (основное)
- `POST /api/ask` — Q&A через RAG + OpenAI.
- `POST /api/dialog/clear` — очистка краткосрочного контекста уточнений.
- `POST /api/reindex` — переиндексация KB.
- `GET /api/debug/retrieval` — отладка retrieval/rerank по запросу (`q`, `limit`).
- `GET /api/documents` — список документов (`q`, `process`, `forms_only`).
- `POST /api/actions` — создать локальное действие (заявка/обращение).
- `GET /api/actions` — список локальных действий.
- `GET /api/files/{file_path}` — открыть/скачать файл KB.

## Проверка готовности (DoD)
- Локальный запуск: ✅
- OpenAI ключ через окружение: ✅
- 3 процесса и 3 сценария MVP: ✅
- RAG по локальной KB: ✅
- Источники в каждом ответе: ✅
- No-hallucination fallback: ✅
- Открытие/скачивание файлов из UI: ✅
# ai_assistant
# ai_assistant
# ai_assistant
